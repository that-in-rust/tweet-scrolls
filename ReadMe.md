# Tweet-Scrolls ğŸ“œ
*Transform Twitter archives into organized conversation intelligence*

**Tweet-Scrolls processes your Twitter archive files and generates structured conversation data with relationship analysis.** Like the Marauder's Map, it reveals hidden patterns in your digital interactions.

## Input â†’ Output

```mermaid
graph TB
    subgraph Input ["ğŸ“¥ What You Provide"]
        A["ğŸ“‚ your-twitter-archive/"]
        A --> B["ğŸ“„ tweets.js<br/>Your tweet history"]
        A --> C["ğŸ’¬ direct-messages.js<br/>Private conversations"]
        A --> D["ğŸ“‹ direct-message-headers.js<br/>Conversation metadata"]
    end
    
    subgraph Output ["ğŸ“¤ What You Get"]
        E["ğŸ“ output_username_timestamp/"]
        E --> F["ğŸ“Š threads_*.csv<br/>Tweet conversations (structured)"]
        E --> G["ğŸ“ threads_*.txt<br/>Tweet conversations (readable)"]
        E --> H["ğŸ’¬ dm_threads_*.csv<br/>DM conversations (structured)"]
        E --> I["ğŸ’­ dm_threads_*.txt<br/>DM conversations (readable)"]
        E --> J["ğŸ“ˆ timeline_analysis_*.csv<br/>Activity patterns (structured)"]
        E --> K["ğŸ“‹ timeline_analysis_*.txt<br/>Activity insights (readable)"]
        E --> L["ğŸ‘¥ relationship_profiles_*/<br/>Individual relationship analysis"]
        L --> M["ğŸ“„ user_*_profile.txt<br/>Per-person interaction history"]
        L --> N["â° interaction_timeline.txt<br/>Chronological activity log"]
        L --> O["ğŸ¤– llm_analysis_prompts.txt<br/>AI-ready analysis questions"]
    end
    
    Input --> Output
    
    style Input fill:#e1f5fe
    style Output fill:#f3e5f5
```

### Key Capabilities
- **Thread Reconstruction**: Connects all replies into complete conversations
- **DM Organization**: Converts message threads into readable conversation flows
- **Relationship Mapping**: Identifies your most frequent interaction partners
- **Timeline Analysis**: Shows when you're most active and interaction patterns
- **Privacy Protection**: All processing happens locally, user IDs are anonymized

## Installation & Usage

### Requirements
- Rust 1.70+ ([install here](https://rustup.rs))
- Your Twitter archive (download from Twitter/X settings)

### Quick Start
```bash
git clone https://github.com/yourusername/tweet-scrolls.git
cd tweet-scrolls
cargo build --release

# Process your archive
./target/release/tweet-scrolls /path/to/your/twitter/archive
```

### Usage Options
```bash
# Basic usage (recommended)
./target/release/tweet-scrolls /path/to/archive

# Custom output location
./target/release/tweet-scrolls /path/to/archive /path/to/output

# Interactive mode
./target/release/tweet-scrolls
```

## User Journey

### ğŸ—ï¸ How It Works: From Raw Data to LLM-Ready Gold

```mermaid
flowchart LR
    subgraph Step1 ["ğŸ” Step 1: Discovery"]
        A1["ğŸ“‚ Auto-detect files<br/>â€¢ tweets.js<br/>â€¢ direct-messages.js<br/>â€¢ headers.js"]
        A2["ğŸ“ Create output directory<br/>â€¢ Timestamped naming<br/>â€¢ Safe file structure"]
        A3["ğŸ›¡ï¸ Initialize privacy<br/>â€¢ Local processing only<br/>â€¢ No network calls"]
    end
    
    subgraph Step2 ["ğŸ§  Step 2: Processing"]
        B1["ğŸ§µ Thread Building<br/>â€¢ Connect all replies<br/>â€¢ Build conversations"]
        B2["ğŸ’¬ DM Organization<br/>â€¢ Add timestamps<br/>â€¢ Smart timing<br/>â€¢ A/B participants"]
        B3["ğŸ” Anonymization<br/>â€¢ Blake3 hash user IDs<br/>â€¢ Protect identity"]
    end
    
    subgraph Step3 ["ğŸ¯ Step 3: Intelligence"]
        C1["ğŸ“Š CSV Data Files<br/>â€¢ Structured data<br/>â€¢ Analysis ready"]
        C2["ğŸ“ Human-Readable<br/>â€¢ Natural flow<br/>â€¢ Conversation style"]
        C3["ğŸ¤– LLM Prompts<br/>â€¢ Relationship maps<br/>â€¢ Behavioral patterns<br/>â€¢ AI analysis"]
    end
    
    Step1 --> Step2
    Step2 --> Step3
    
    style Step1 fill:#e8f5e8
    style Step2 fill:#fff3e0
    style Step3 fill:#f3e5f5
```

**The Magic**: Like a digital archaeologist, Tweet-Scrolls discovers your Twitter archive files, intelligently reconstructs conversation threads, and transforms them into LLM-ready insights - all while keeping your data safe and local.

### Thread Compilation Example

Like transforming scattered pages into a coherent storybook, Tweet-Scrolls compiles individual JSON messages into cohesive conversation threads that are easily digestible by Large Language Models.

```mermaid
flowchart TD
    subgraph Input ["ğŸ“„ Raw JSON Messages"]
        A1["msg1: 'Hello!'<br/>sender: A<br/>id: 1"]
        A2["msg2: 'Hi there!'<br/>sender: B<br/>id: 2"]
        A3["msg3: 'How are you?'<br/>sender: A<br/>id: 3"]
    end
    
    subgraph Processing ["ğŸ§  Transformation Engine"]
        B1["ğŸ” Parse Content<br/>Extract text & metadata"]
        B2["â° Add Timestamps<br/>Calculate relative timing"]
        B3["ğŸ§µ Thread Assembly<br/>Order chronologically"]
        B4["ğŸ” Anonymization<br/>Hash user identifiers"]
    end
    
    subgraph Output ["ğŸ’¬ LLM-Ready Thread"]
        C1["A: Hello!<br/>(5 minutes later)<br/>B: Hi there!<br/>(5 minutes later)<br/>A: How are you?"]
        C2["ğŸ“Š Metadata:<br/>â€¢ 3 messages<br/>â€¢ 10 min duration<br/>â€¢ A â†” B participants<br/>â€¢ Blake3 anonymized"]
    end
    
    Input --> Processing
    Processing --> Output
    
    A1 --> B1
    A2 --> B2
    A3 --> B3
    B1 --> B4
    B2 --> B4
    B3 --> B4
    B4 --> C1
    B4 --> C2
    
    style Input fill:#ffe0e0
    style Processing fill:#fff3e0
    style Output fill:#e8f5e8
```

**The Transformation**: Individual JSON objects become natural conversation flow with timing context and participant anonymization - perfect for LLM analysis and pattern recognition.

## File Details

| File | Content | Purpose |
|------|---------|---------|
| `threads_*.csv` | Tweet conversations with metadata | Data analysis |
| `threads_*.txt` | Human-readable tweet threads | Review conversations |
| `dm_threads_*.csv` | DM conversations with timing | Data analysis |
| `dm_threads_*.txt` | Human-readable DM threads | Review private messages |
| `timeline_analysis_*.csv` | Activity patterns and statistics | Behavioral analysis |
| `timeline_analysis_*.txt` | Activity insights and summaries | Understanding patterns |
| `relationship_profiles_*/` | Individual relationship analysis | AI-ready insights |

## Privacy & Security

**All processing happens locally** - your data never leaves your machine. User IDs are anonymized using Blake3 hashing for privacy protection.

### Built-in Safety Features
- Local processing only (no network connections)
- Automatic git protection for private data
- Blake3 anonymization for user identifiers
- Comprehensive .gitignore protection

```bash
# Safety check before commits
./check_data_safety.sh
```

## Performance

- Processes 50,000+ tweets efficiently
- Handles large DM archives with streaming
- Parallel processing for optimal speed
- Memory-efficient design

## Development

```bash
# Run tests
cargo test

# Check code quality
cargo clippy
```

### Architecture
- `models/` - Data structures for tweets, DMs, and analysis
- `processing/` - JSON parsing and data transformation  
- `relationship/` - Intelligence extraction and report generation
- `services/` - Timeline analysis and pattern detection

## File Splitter Utility

Split large archive files into manageable chunks:

```bash
cargo build --release --bin file-splitter
./target/release/file-splitter large_archive.js

# Custom options
./target/release/file-splitter -i tweets.js -s 5M -o chunks/
```

## License

MIT License

---

*Like the Marauder's Map, Tweet-Scrolls reveals the hidden patterns in your digital world.*

## Architecture

```mermaid
graph TD
    subgraph CLI ["ğŸ–¥ï¸ CLI Layer"]
        A1["main.rs<br/>Entry point<br/>User interaction"]
        A2["cli.rs<br/>Command line interface<br/>Argument parsing<br/>Interactive mode"]
    end
    
    subgraph Processing ["âš™ï¸ Processing Layer"]
        B1["data_structures.rs<br/>Core data structures"]
        B2["file_io.rs<br/>File input/output"]
        B3["tweets.rs<br/>Tweet parsing"]
        B4["direct_messages.rs<br/>DM parsing"]
        B5["reply_threads.rs<br/>Thread reconstruction"]
        B6["dm_threads.rs<br/>DM threading"]
    end
    
    subgraph Analysis ["ğŸ” Analysis Layer"]
        C1["analyzer.rs<br/>Core analysis engine"]
        C2["timeline_analyzer.rs<br/>Timeline patterns"]
        C3["relationship/analyzer.rs<br/>Relationship intelligence"]
        C4["anonymization.rs<br/>Privacy protection"]
    end
    
    subgraph Output ["ğŸ“¤ Output Layer"]
        D1["file_generation.rs<br/>File orchestration"]
        D2["text_generators.rs<br/>Human-readable text"]
        D3["prompts_generator.rs<br/>LLM analysis prompts"]
        D4["enhanced_csv_writer.rs<br/>CSV output"]
    end
    
    subgraph Models ["ğŸ“¦ Data Models"]
        E1["direct_message.rs<br/>DM structures"]
        E2["profile.rs<br/>User profiles"]
        E3["statistics.rs<br/>Statistical data"]
        E4["timeline.rs<br/>Timeline structures"]
    end
    
    CLI --> Processing
    Processing --> Analysis
    Analysis --> Output
    Models -.-> Processing
    Models -.-> Analysis
    Models -.-> Output
    
    style CLI fill:#e3f2fd
    style Processing fill:#fff3e0
    style Analysis fill:#f3e5f5
    style Output fill:#e8f5e8
    style Models fill:#fce4ec
```

## LLM Assimilation Journey

*"Like the Sorting Hat understanding a student's mind..."*

```mermaid
graph TB
    subgraph Files ["ğŸ“Š Generated Data Files"]
        A1["threads_*.csv<br/>Tweet conversations<br/>(structured)"]
        A2["dm_threads_*.csv<br/>DM conversations<br/>(structured)"]
        A3["timeline_analysis_*.csv<br/>Activity patterns<br/>(structured)"]
        A4["*.txt files<br/>Human-readable<br/>formats"]
    end
    
    subgraph Questions ["ğŸ§  Ready-Made Analysis Questions"]
        B1["'Who do I interact<br/>with most frequently?'"]
        B2["'When am I<br/>most active?'"]
        B3["'How has my communication<br/>style evolved?'"]
        B4["'What are my<br/>conversation patterns?'"]
    end
    
    subgraph Intelligence ["ğŸ¯ LLM-Ready Intelligence"]
        C1["ğŸ“ˆ Relationship Analysis<br/>â€¢ Interaction frequency<br/>â€¢ Communication patterns"]
        C2["â° Timeline Patterns<br/>â€¢ Peak activity hours<br/>â€¢ Response timing"]
        C3["ğŸ” Behavioral Insights<br/>â€¢ Style evolution<br/>â€¢ Pattern recognition"]
        C4["ğŸ” Privacy Protected<br/>â€¢ Blake3 anonymization<br/>â€¢ Local processing"]
    end
    
    Files --> Intelligence
    Questions --> Intelligence
    
    A1 --> C1
    A2 --> C1
    A3 --> C2
    A4 --> C3
    
    B1 --> C1
    B2 --> C2
    B3 --> C3
    B4 --> C3
    
    style Files fill:#e3f2fd
    style Questions fill:#fff3e0
    style Intelligence fill:#e8f5e8
```

**The Result**: Your digital conversations become structured intelligence that LLMs can analyze for relationship patterns, behavioral insights, and communication evolution - all with privacy-first anonymization.

---

*Like the Marauder's Map, Tweet-Scrolls reveals the hidden patterns in your digital world.*